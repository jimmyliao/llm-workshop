{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time=2024-04-16T23:01:06.445+08:00 level=INFO source=images.go:804 msg=\"total blobs: 22\"\n",
      "time=2024-04-16T23:01:06.446+08:00 level=INFO source=images.go:811 msg=\"total unused blobs removed: 0\"\n",
      "time=2024-04-16T23:01:06.447+08:00 level=INFO source=routes.go:1118 msg=\"Listening on 127.0.0.1:11434 (version 0.1.31)\"\n",
      "time=2024-04-16T23:01:06.448+08:00 level=INFO source=payload_common.go:113 msg=\"Extracting dynamic libraries to /var/folders/wd/k6f6pm051cq8gm__9_vyfzfm0000gp/T/ollama3550360374/runners ...\"\n",
      "time=2024-04-16T23:01:06.474+08:00 level=INFO source=payload_common.go:140 msg=\"Dynamic LLM libraries [metal]\"\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you're running on linux or colab\n",
    "# !curl -fsSL https://ollama.com/install.sh | bash -s -- -b /usr/local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['ollama', 'serve']>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=2024-04-16T23:01:32.246+08:00 level=INFO source=images.go:804 msg=\"total blobs: 22\"\n",
      "time=2024-04-16T23:01:32.247+08:00 level=INFO source=images.go:811 msg=\"total unused blobs removed: 0\"\n",
      "time=2024-04-16T23:01:32.247+08:00 level=INFO source=routes.go:1118 msg=\"Listening on 127.0.0.1:11434 (version 0.1.31)\"\n",
      "time=2024-04-16T23:01:32.250+08:00 level=INFO source=payload_common.go:113 msg=\"Extracting dynamic libraries to /var/folders/wd/k6f6pm051cq8gm__9_vyfzfm0000gp/T/ollama3228571723/runners ...\"\n",
      "time=2024-04-16T23:01:32.278+08:00 level=INFO source=payload_common.go:140 msg=\"Dynamic LLM libraries [metal]\"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.Popen([\"ollama\", \"serve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull gemma:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GIN] 2024/04/16 - 23:03:51 | 200 |      18.625Âµs |       127.0.0.1 | HEAD     \"/\"\n",
      "[GIN] 2024/04/16 - 23:03:51 | 200 |    1.702708ms |       127.0.0.1 | GET      \"/api/tags\"\n",
      "NAME                         \tID          \tSIZE  \tMODIFIED       \n",
      "gemma:7b                     \ta72c7f4d0a15\t5.0 GB\t15 seconds ago\t\n",
      "llama2:latest                \t78e26419b446\t3.8 GB\t6 weeks ago   \t\n",
      "mistral:7b-instruct-v0.2-q8_0\t3f321fd2a1c3\t7.7 GB\t6 weeks ago   \t\n",
      "nous-hermes2-mixtral:latest  \t599da8dce2c1\t26 GB \t5 weeks ago   \t\n",
      "wizardlm:70b-llama2-q3_K_M   \t56a8ed83f414\t33 GB \t5 weeks ago   \t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index-llms-ollama llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x162899ed0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x11d39a340>, completion_to_prompt=<function default_completion_to_prompt at 0x11d415b20>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='gemma:7b', temperature=0.75, context_window=3900, request_timeout=30.0, prompt_key='prompt', additional_kwargs={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"gemma:7b\", request_timeout=30.0)\n",
    "\n",
    "# check if the model is available\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":829,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279916}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":6,\"n_past_se\":0,\"n_prompt_tokens_processed\":11,\"slot_id\":0,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279916}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":6,\"slot_id\":0,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279916}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":272,\"msg\":\"prompt eval time     =     822.54 ms /    11 tokens (   74.78 ms per token,    13.37 tokens per second)\",\"n_prompt_tokens_processed\":11,\"n_tokens_second\":13.373177296721625,\"slot_id\":0,\"t_prompt_processing\":822.542,\"t_token\":74.77654545454546,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279920}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":286,\"msg\":\"generation eval time =    2803.05 ms /    16 runs   (  175.19 ms per token,     5.71 tokens per second)\",\"n_decoded\":16,\"n_tokens_second\":5.708057815490599,\"slot_id\":0,\"t_token\":175.1909375,\"t_token_generation\":2803.055,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279920}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":295,\"msg\":\"          total time =    3625.60 ms\",\"slot_id\":0,\"t_prompt_processing\":822.542,\"t_token_generation\":2803.055,\"t_total\":3625.5969999999998,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279920}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1644,\"msg\":\"slot released\",\"n_cache_tokens\":33,\"n_ctx\":3904,\"n_past\":32,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":136,\"tid\":\"0x17fe87000\",\"timestamp\":1713279920,\"truncated\":false}\n",
      "[GIN] 2024/04/16 - 23:05:20 | 200 |  3.630117667s |       127.0.0.1 | POST     \"/api/generate\"\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(\"Who is the author of Harry Potter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of the Harry Potter series is **J. K. Rowling**.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":829,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280005}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":48,\"slot_id\":0,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280005}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280005}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":272,\"msg\":\"prompt eval time     =    1405.40 ms /    48 tokens (   29.28 ms per token,    34.15 tokens per second)\",\"n_prompt_tokens_processed\":48,\"n_tokens_second\":34.15385600592,\"slot_id\":0,\"t_prompt_processing\":1405.405,\"t_token\":29.27927083333333,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280009}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":286,\"msg\":\"generation eval time =    2330.95 ms /    13 runs   (  179.30 ms per token,     5.58 tokens per second)\",\"n_decoded\":13,\"n_tokens_second\":5.577129991745848,\"slot_id\":0,\"t_token\":179.3036923076923,\"t_token_generation\":2330.948,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280009}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":295,\"msg\":\"          total time =    3736.35 ms\",\"slot_id\":0,\"t_prompt_processing\":1405.405,\"t_token_generation\":2330.948,\"t_total\":3736.353,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280009}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1644,\"msg\":\"slot released\",\"n_cache_tokens\":65,\"n_ctx\":3904,\"n_past\":64,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":155,\"tid\":\"0x17fe87000\",\"timestamp\":1713280009,\"truncated\":false}\n",
      "[GIN] 2024/04/16 - 23:06:49 | 200 |  3.739204041s |       127.0.0.1 | POST     \"/api/chat\"\n"
     ]
    }
   ],
   "source": [
    "# Call Chat completion with a list of messages\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        speaker=\"user\",\n",
    "        content=\"What is the capital of France?\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        speaker=\"system\",\n",
    "        content=\"The capital of France is Paris.\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        speaker=\"user\",\n",
    "        content=\"Who is the president of the United States?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "resp = llm.chat(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The current president of the United States is **Joe Biden**.', additional_kwargs={}), raw={'model': 'gemma:7b', 'created_at': '2024-04-16T15:06:49.681937Z', 'message': {'role': 'assistant', 'content': 'The current president of the United States is **Joe Biden**.'}, 'done': True, 'total_duration': 3739030459, 'load_duration': 1129917, 'prompt_eval_count': 48, 'prompt_eval_duration': 1405405000, 'eval_count': 13, 'eval_duration': 2330948000}, delta=None, logprobs=None, additional_kwargs={'model': 'gemma:7b', 'created_at': '2024-04-16T15:06:49.681937Z', 'done': True, 'total_duration': 3739030459, 'load_duration': 1129917, 'prompt_eval_count': 48, 'prompt_eval_duration': 1405405000, 'eval_count': 13, 'eval_duration': 2330948000})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":829,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280142}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":9,\"n_past_se\":0,\"n_prompt_tokens_processed\":16,\"slot_id\":0,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280142}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":9,\"slot_id\":0,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280142}\n",
      "Paul Graham is an American entrepreneur, investor, and author. He co-founded Palantir Technologies and was a founding partner of Y Combinator. He's also known for his investments in companies like Airbnb, Dropbox, and Cruise Automation. Graham is an influential figure in Silicon Valley, known for his insights on technology, startups, and entrepreneurship.{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":272,\"msg\":\"prompt eval time     =     393.27 ms /    16 tokens (   24.58 ms per token,    40.68 tokens per second)\",\"n_prompt_tokens_processed\":16,\"n_tokens_second\":40.684723903292415,\"slot_id\":0,\"t_prompt_processing\":393.268,\"t_token\":24.57925,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280154}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":286,\"msg\":\"generation eval time =   12453.37 ms /    72 runs   (  172.96 ms per token,     5.78 tokens per second)\",\"n_decoded\":72,\"n_tokens_second\":5.78156802388173,\"slot_id\":0,\"t_token\":172.96345833333334,\"t_token_generation\":12453.369,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280154}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":295,\"msg\":\"          total time =   12846.64 ms\",\"slot_id\":0,\"t_prompt_processing\":393.268,\"t_token_generation\":12453.369,\"t_total\":12846.637,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280154}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1644,\"msg\":\"slot released\",\"n_cache_tokens\":97,\"n_ctx\":3904,\"n_past\":96,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":512,\"tid\":\"0x17fe87000\",\"timestamp\":1713280154,\"truncated\":false}\n",
      "[GIN] 2024/04/16 - 23:09:14 | 200 | 12.853063416s |       127.0.0.1 | POST     \"/api/generate\"\n"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "response = llm.stream_complete(\"Who is Paul Graham? Write a short biography within 100 words.\")\n",
    "\n",
    "for message in response:\n",
    "    print(message.delta, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stream_chat endpoint\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":829,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280193}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1812,\"msg\":\"slot progression\",\"n_past\":4,\"n_past_se\":0,\"n_prompt_tokens_processed\":17,\"slot_id\":0,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280193}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":4,\"slot_id\":0,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280193}\n",
      "Avast there, matey! I be known as Zephyr Breeze, a swashbucklin' pirate with a heart as bold as the ocean's roar! My sails are a symphony of vibrant hues, for I believe a pirate's life ain't for the faint of heart. I live for the thrill of the chase, the taste of freedom, and the bounty of riches that awaits those who dare to defy the crown!{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":272,\"msg\":\"prompt eval time     =     591.09 ms /    17 tokens (   34.77 ms per token,    28.76 tokens per second)\",\"n_prompt_tokens_processed\":17,\"n_tokens_second\":28.760668939323445,\"slot_id\":0,\"t_prompt_processing\":591.085,\"t_token\":34.769705882352945,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280209}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":286,\"msg\":\"generation eval time =   15455.88 ms /    89 runs   (  173.66 ms per token,     5.76 tokens per second)\",\"n_decoded\":89,\"n_tokens_second\":5.758325163305131,\"slot_id\":0,\"t_token\":173.66160674157302,\"t_token_generation\":15455.883,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280209}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":295,\"msg\":\"          total time =   16046.97 ms\",\"slot_id\":0,\"t_prompt_processing\":591.085,\"t_token_generation\":15455.883,\"t_total\":16046.968,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280209}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1644,\"msg\":\"slot released\",\"n_cache_tokens\":110,\"n_ctx\":3904,\"n_past\":109,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":587,\"tid\":\"0x17fe87000\",\"timestamp\":1713280209,\"truncated\":false}\n",
      "[GIN] 2024/04/16 - 23:10:09 | 200 | 16.048600583s |       127.0.0.1 | POST     \"/api/chat\"\n"
     ]
    }
   ],
   "source": [
    "for message in resp:\n",
    "    print(message.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-nb-v3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
