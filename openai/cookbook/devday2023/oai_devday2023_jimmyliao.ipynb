{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspiring by [@ihower](https://ihower.tw/). Thanks!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Dev Day 2023 Feature Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OpenAI API Key from user imput\n",
    "\n",
    "#### You can run this Jupyter Notebook with VSCode or Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy shortuuid requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use getpass to read password, also save to the enviroment variable\n",
    "import os, requests, json\n",
    "from pprint import pp\n",
    "import getpass\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter your OpenAI API key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model='gpt-3.5-turbo', temperature=0, max_tokens=300):\n",
    "    api_url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=60)\n",
    "\n",
    "    resp_text = json.loads(response.text)\n",
    "    resp_status = response.status_code\n",
    "    print(resp_text)\n",
    "    print(resp_status)\n",
    "    if resp_status == 200:\n",
    "        return resp_text[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return resp_text[\"error\"]['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: GPT-4 Vision Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get random image from Lorem Picsum, preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://fastly.picsum.photos/id/1082/800/1280.jpg?hmac=Y1Dx1-ZqK-D7ZQ4jzY6HDFrLWv-iN_WfP-MUdsACvks\" width=\"200\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## preview the image_url\n",
    "from IPython.display import Image\n",
    "request_image_url = 'https://picsum.photos/800/1280'\n",
    "response = requests.get(request_image_url, allow_redirects=True)\n",
    "image_url = response.url\n",
    "\n",
    "Image(url=image_url, width=200, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate text description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8J1k1Wjg8p5XHUyladWfg1uwuGCCi', 'object': 'chat.completion', 'created': 1699545617, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 1128, 'completion_tokens': 108, 'total_tokens': 1236}, 'choices': [{'message': {'role': 'assistant', 'content': '這是一張黑白照片，展示了雙手在彈奏鋼琴。手指觸及黑白琴鍵，顯示出經驗的痕跡。照片背景模糊地顯示鋼琴品牌“Huberger & Co”。整體氛圍藝術而深沉。'}, 'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0}]}\n",
      "200\n",
      "'這是一張黑白照片，展示了雙手在彈奏鋼琴。手指觸及黑白琴鍵，顯示出經驗的痕跡。照片背景模糊地顯示鋼琴品牌“Huberger & Co”。整體氛圍藝術而深沉。'\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"請以100字內描述這張照片\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": image_url\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = get_completion(messages, model='gpt-4-vision-preview')\n",
    "pp(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2: Assistant API Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step0: Upload a PDF file with OpenAI File API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_id: file-t0mUO7iL7yRmeGKUjSs7CbPZ, file_name: 2305.06983.pdf\n"
     ]
    }
   ],
   "source": [
    "# OpenAI assistant API with retrieval\n",
    "\n",
    "## pdf from arXiv: https://arxiv.org/pdf/2305.06983.pdf\n",
    "\n",
    "doc_source = 'https://arxiv.org/pdf/2305.06983.pdf'\n",
    "\n",
    "filename = doc_source.split('/')[-1]\n",
    "\n",
    "## check if the file exists\n",
    "import os.path\n",
    "if not os.path.isfile(filename):\n",
    "    # wget with specific user agent\n",
    "    !wget -U \"Mozilla/5.0\" -O $filename $doc_source\n",
    "    print('downloaded file:', filename)    \n",
    "    \n",
    "\n",
    "files = [\n",
    "    ('file',\n",
    "      (\n",
    "          filename,\n",
    "          open(filename, 'rb'),\n",
    "          \"application/octet-stream\"\n",
    "      )\n",
    "    )\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"purpose\": \"assistants\",    \n",
    "}\n",
    "\n",
    "## List the files\n",
    "# response = requests.get('https://api.openai.com/v1/files', headers=headers)\n",
    "# print(json.loads(response.text))\n",
    "\n",
    "### Upload the file to OpenAI\n",
    "\n",
    "response = requests.post('https://api.openai.com/v1/files', headers=headers, data=data, files=files)\n",
    "\n",
    "# print(json.loads(response.text))\n",
    "\n",
    "## Get file id and save to the environment variable\n",
    "file_id = json.loads(response.text)['id']\n",
    "file_name = json.loads(response.text)['filename']\n",
    "os.environ['OPENAI_FILE_ID'] = file_id\n",
    "\n",
    "print(f\"file_id: {file_id}, file_name: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): List all uploaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list',\n",
      " 'has_more': False,\n",
      " 'data': [{'object': 'file',\n",
      "           'id': 'file-t0mUO7iL7yRmeGKUjSs7CbPZ',\n",
      "           'purpose': 'assistants',\n",
      "           'filename': '2305.06983.pdf',\n",
      "           'bytes': 850866,\n",
      "           'created_at': 1699545644,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-DetKu8e8ZJWEu6Iweg988Oz8',\n",
      "           'purpose': 'assistants',\n",
      "           'filename': '停車場資訊.pdf',\n",
      "           'bytes': 182055,\n",
      "           'created_at': 1699444518,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-ffoOkEmb5gj3djWxvMJP8xYJ',\n",
      "           'purpose': 'fine-tune-results',\n",
      "           'filename': 'compiled_results.csv',\n",
      "           'bytes': 215048,\n",
      "           'created_at': 1675331528,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-XJ67TkoFSKM6QgwzsEr03YOl',\n",
      "           'purpose': 'fine-tune',\n",
      "           'filename': 'sport2_prepared_valid.jsonl',\n",
      "           'bytes': 387349,\n",
      "           'created_at': 1675330133,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-0oYDxq1R5WgoGuMTHvcVXGYR',\n",
      "           'purpose': 'fine-tune',\n",
      "           'filename': 'sport2_prepared_train.jsonl',\n",
      "           'bytes': 1519036,\n",
      "           'created_at': 1675330131,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-xREhbH04eGaasZCkwtQo8kpm',\n",
      "           'purpose': 'fine-tune',\n",
      "           'filename': 'sport2_prepared_valid.jsonl',\n",
      "           'bytes': 387349,\n",
      "           'created_at': 1675328948,\n",
      "           'status': 'processed',\n",
      "           'status_details': None},\n",
      "          {'object': 'file',\n",
      "           'id': 'file-BNNXhpyv7WRbFP90Vh3M9cog',\n",
      "           'purpose': 'fine-tune',\n",
      "           'filename': 'sport2_prepared_train.jsonl',\n",
      "           'bytes': 1519036,\n",
      "           'created_at': 1675328946,\n",
      "           'status': 'processed',\n",
      "           'status_details': None}]}\n"
     ]
    }
   ],
   "source": [
    "## List the files\n",
    "response = requests.get('https://api.openai.com/v1/files', headers=headers)\n",
    "pp(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: Create the assistant with retrieval\n",
    "##### The indexing process will be started once the assistant is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      " 'object': 'assistant',\n",
      " 'created_at': 1699545656,\n",
      " 'name': 'assistant-h4AuruGg',\n",
      " 'description': None,\n",
      " 'model': 'gpt-4-1106-preview',\n",
      " 'instructions': '\\n'\n",
      "                 '    You are a customer support chatbot. Use your knowledge '\n",
      "                 'base to best respond to customer queries.\\n',\n",
      " 'tools': [{'type': 'retrieval'}],\n",
      " 'file_ids': ['file-t0mUO7iL7yRmeGKUjSs7CbPZ'],\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "import shortuuid\n",
    "\n",
    "## Create the assistant with retrieval\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "### assistant_name should be unique with short UUID format\n",
    "assistant_name = f'assistant-' + shortuuid.uuid()[0:8]\n",
    "\n",
    "# assistant_name = 'jimmyliao-assistant-1'\n",
    "instructions = \"\"\"\n",
    "    You are a customer support chatbot. Use your knowledge base to best respond to customer queries.\n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4-1106-preview\", \n",
    "    \"name\": assistant_name, \n",
    "    \"tools\": [{\"type\": \"retrieval\"}],\n",
    "    \"instructions\": instructions,\n",
    "    \"file_ids\": [file_id],\n",
    "}\n",
    "\n",
    "response = requests.post('https://api.openai.com/v1/assistants', headers=headers, data=json.dumps(payload))\n",
    "\n",
    "assistant_id = json.loads(response.text)['id']\n",
    "pp(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2: Create Thread\n",
    "#### Step3: Add the user message to the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'object': 'thread',\n",
      " 'created_at': 1699545669,\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "## Create thread \n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "### Add the user message to the thread\n",
    "payload = { \"messages\": [ { \"role\": \"user\", \"content\": \"write 100-word summary for this article.\"} ] }\n",
    "\n",
    "response = requests.post('https://api.openai.com/v1/threads', headers=headers, data=json.dumps(payload))\n",
    "\n",
    "thread_id = json.loads(response.text)['id']\n",
    "\n",
    "pp(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4: Run the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'run_xyJA4T24pY2Uub93ZNemRPfP',\n",
      " 'object': 'thread.run',\n",
      " 'created_at': 1699545674,\n",
      " 'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      " 'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'status': 'queued',\n",
      " 'started_at': None,\n",
      " 'expires_at': 1699546274,\n",
      " 'cancelled_at': None,\n",
      " 'failed_at': None,\n",
      " 'completed_at': None,\n",
      " 'last_error': None,\n",
      " 'model': 'gpt-4-1106-preview',\n",
      " 'instructions': '\\n'\n",
      "                 '    You are a customer support chatbot. Use your knowledge '\n",
      "                 'base to best respond to customer queries.\\n',\n",
      " 'tools': [{'type': 'retrieval'}],\n",
      " 'file_ids': ['file-t0mUO7iL7yRmeGKUjSs7CbPZ'],\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "## Execute (assistant + thread).run, and get the response\n",
    "\n",
    "payload = {\n",
    "    \"assistant_id\": assistant_id,\n",
    "    # \"thread_id\": thread_id,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "response = requests.post(f\"https://api.openai.com/v1/threads/{thread_id}/runs\", headers = headers, data = json.dumps(payload) )\n",
    "obj = json.loads(response.text)\n",
    "\n",
    "run_id = obj['id']\n",
    "pp(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Monitor the Thread run status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'run_xyJA4T24pY2Uub93ZNemRPfP',\n",
      " 'object': 'thread.run',\n",
      " 'created_at': 1699545674,\n",
      " 'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      " 'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'status': 'completed',\n",
      " 'started_at': 1699545674,\n",
      " 'expires_at': None,\n",
      " 'cancelled_at': None,\n",
      " 'failed_at': None,\n",
      " 'completed_at': 1699545683,\n",
      " 'last_error': None,\n",
      " 'model': 'gpt-4-1106-preview',\n",
      " 'instructions': '\\n'\n",
      "                 '    You are a customer support chatbot. Use your knowledge '\n",
      "                 'base to best respond to customer queries.\\n',\n",
      " 'tools': [{'type': 'retrieval'}],\n",
      " 'file_ids': ['file-t0mUO7iL7yRmeGKUjSs7CbPZ'],\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "## Monitor the run status\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "response = requests.get(f\"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\", headers = headers)\n",
    "\n",
    "obj = json.loads(response.text)\n",
    "pp(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step5: Get the Assistant response from the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list',\n",
      " 'data': [{'id': 'msg_Opx5NyEJiLxFLqzybgQAMOCM',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545676,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'assistant',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'The article introduces '\n",
      "                                          'Forward-Looking Active REtrieval '\n",
      "                                          'augmented generation (FLARE), a '\n",
      "                                          'method enhancing large language '\n",
      "                                          'models (LMs) to reduce '\n",
      "                                          'hallucinations and factually '\n",
      "                                          'incorrect outputs by actively '\n",
      "                                          'retrieving information during text '\n",
      "                                          'generation. Unlike traditional '\n",
      "                                          'retrieval-augmented LMs, which '\n",
      "                                          'fetch information once based on the '\n",
      "                                          'initial input, FLARE iteratively '\n",
      "                                          'predicts upcoming content to '\n",
      "                                          'retrieve relevant documents as '\n",
      "                                          'needed throughout the generation. '\n",
      "                                          'The approach addresses the '\n",
      "                                          'limitations of single-time '\n",
      "                                          'retrieval, particularly evident in '\n",
      "                                          'long-form, knowledge-intensive '\n",
      "                                          'tasks like long-form QA and '\n",
      "                                          'summarization. FLARE has been '\n",
      "                                          'tested extensively, showing '\n",
      "                                          'superior or competitive performance '\n",
      "                                          'on various long-form generation '\n",
      "                                          'tasks.',\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      "           'run_id': 'run_xyJA4T24pY2Uub93ZNemRPfP',\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_kNk9laIGxmDGd7Rh6j2zhLM8',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545669,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'user',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'write 100-word summary for this '\n",
      "                                          'article.',\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': None,\n",
      "           'run_id': None,\n",
      "           'metadata': {}}],\n",
      " 'first_id': 'msg_Opx5NyEJiLxFLqzybgQAMOCM',\n",
      " 'last_id': 'msg_kNk9laIGxmDGd7Rh6j2zhLM8',\n",
      " 'has_more': False}\n"
     ]
    }
   ],
   "source": [
    "## Get the assistant response from thread\n",
    "\n",
    "headers = { \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\", \"Content-Type\": \"application/json\", \"OpenAI-Beta\": \"assistants=v1\" }\n",
    "response = requests.get(f\"https://api.openai.com/v1/threads/{thread_id}/messages\", headers = headers )\n",
    "obj = json.loads(response.text)\n",
    "\n",
    "pp(obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Add a new message to the thread, and run the Assistant Thread again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'msg_AwmTYjYniBQtkNV84ISR0OVK',\n",
      " 'object': 'thread.message',\n",
      " 'created_at': 1699545850,\n",
      " 'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'role': 'user',\n",
      " 'content': [{'type': 'text', 'text': {'value': '有哪些作者？', 'annotations': []}}],\n",
      " 'file_ids': [],\n",
      " 'assistant_id': None,\n",
      " 'run_id': None,\n",
      " 'metadata': {}}\n",
      "{'id': 'run_ze2nNTwTyMmQrIQ7px454kuP',\n",
      " 'object': 'thread.run',\n",
      " 'created_at': 1699545851,\n",
      " 'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      " 'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'status': 'queued',\n",
      " 'started_at': None,\n",
      " 'expires_at': 1699546451,\n",
      " 'cancelled_at': None,\n",
      " 'failed_at': None,\n",
      " 'completed_at': None,\n",
      " 'last_error': None,\n",
      " 'model': 'gpt-4-1106-preview',\n",
      " 'instructions': '\\n'\n",
      "                 '    You are a customer support chatbot. Use your knowledge '\n",
      "                 'base to best respond to customer queries.\\n',\n",
      " 'tools': [{'type': 'retrieval'}],\n",
      " 'file_ids': ['file-t0mUO7iL7yRmeGKUjSs7CbPZ'],\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "## Add a new message to the thread\n",
    "\n",
    "payload = { \"role\": \"user\", \"content\": \"有哪些作者？\" }\n",
    "headers = { \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\", \"Content-Type\": \"application/json\", \"OpenAI-Beta\": \"assistants=v1\" }\n",
    "response = requests.post(f\"https://api.openai.com/v1/threads/{thread_id}/messages\", headers = headers, data = json.dumps(payload) )\n",
    "obj = json.loads(response.text)\n",
    "\n",
    "pp(obj)\n",
    "\n",
    "## Execute (assistant + thread).run, and get the response\n",
    "\n",
    "payload = {\n",
    "    \"assistant_id\": assistant_id,\n",
    "    # \"thread_id\": thread_id,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "response = requests.post(f\"https://api.openai.com/v1/threads/{thread_id}/runs\", headers = headers, data = json.dumps(payload) )\n",
    "obj = json.loads(response.text)\n",
    "\n",
    "# run_id = obj['id']\n",
    "pp(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'run_ze2nNTwTyMmQrIQ7px454kuP',\n",
      " 'object': 'thread.run',\n",
      " 'created_at': 1699545851,\n",
      " 'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      " 'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      " 'status': 'completed',\n",
      " 'started_at': 1699545851,\n",
      " 'expires_at': None,\n",
      " 'cancelled_at': None,\n",
      " 'failed_at': None,\n",
      " 'completed_at': 1699545862,\n",
      " 'last_error': None,\n",
      " 'model': 'gpt-4-1106-preview',\n",
      " 'instructions': '\\n'\n",
      "                 '    You are a customer support chatbot. Use your knowledge '\n",
      "                 'base to best respond to customer queries.\\n',\n",
      " 'tools': [{'type': 'retrieval'}],\n",
      " 'file_ids': ['file-t0mUO7iL7yRmeGKUjSs7CbPZ'],\n",
      " 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "## Monitor the run status\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"OpenAI-Beta\": \"assistants=v1\",\n",
    "}\n",
    "\n",
    "response = requests.get(f\"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\", headers = headers)\n",
    "\n",
    "obj = json.loads(response.text)\n",
    "pp(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Assistant response from the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'list',\n",
      " 'data': [{'id': 'msg_jvNyCQ4UaJRSZH6m7dtqQtHV',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545861,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'assistant',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'The authors of the article are '\n",
      "                                          'Zhengbao Jiang, Frank F. Xu, Luyu '\n",
      "                                          'Gao, Zhiqing Sun, Qian Liu, Jane '\n",
      "                                          'Dwivedi-Yu, Yiming Yang, Jamie '\n",
      "                                          'Callan, and Graham '\n",
      "                                          'Neubig【20†source】.',\n",
      "                                 'annotations': [{'type': 'file_citation',\n",
      "                                                  'text': '【20†source】',\n",
      "                                                  'start_index': 154,\n",
      "                                                  'end_index': 165,\n",
      "                                                  'file_citation': {'file_id': 'file-t0mUO7iL7yRmeGKUjSs7CbPZ',\n",
      "                                                                    'quote': 'Active '\n",
      "                                                                             'Retrieval '\n",
      "                                                                             'Augmented '\n",
      "                                                                             'Generation   '\n",
      "                                                                             'Zhengbao '\n",
      "                                                                             'Jiang1∗  '\n",
      "                                                                             'Frank '\n",
      "                                                                             'F. '\n",
      "                                                                             'Xu1∗  '\n",
      "                                                                             'Luyu '\n",
      "                                                                             'Gao1∗  '\n",
      "                                                                             'Zhiqing '\n",
      "                                                                             'Sun1∗  '\n",
      "                                                                             'Qian '\n",
      "                                                                             'Liu2   '\n",
      "                                                                             'Jane '\n",
      "                                                                             'Dwivedi-Yu3  '\n",
      "                                                                             'Yiming '\n",
      "                                                                             'Yang1  '\n",
      "                                                                             'Jamie '\n",
      "                                                                             'Callan1  '\n",
      "                                                                             'Graham '\n",
      "                                                                             'Neubig1'}}]}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      "           'run_id': 'run_ze2nNTwTyMmQrIQ7px454kuP',\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_Dl1OzNIIsue0viUK6O3XDo36',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545855,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'assistant',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': \"I'm sorry, but the information \"\n",
      "                                          'about the authors is not visible '\n",
      "                                          'currently. It might be located in a '\n",
      "                                          'different section of the document. '\n",
      "                                          \"I'll search again.\",\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      "           'run_id': 'run_ze2nNTwTyMmQrIQ7px454kuP',\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_Uv9yKNx788lLArhqeFwtI3qC',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545852,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'assistant',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'I apologize, but it seems that the '\n",
      "                                          'search for the authors did not '\n",
      "                                          'return any results. Let me try a '\n",
      "                                          'different approach to locate the '\n",
      "                                          'authors of the article for you.',\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      "           'run_id': 'run_ze2nNTwTyMmQrIQ7px454kuP',\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_AwmTYjYniBQtkNV84ISR0OVK',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545850,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'user',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': '有哪些作者？', 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': None,\n",
      "           'run_id': None,\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_NXG76Vdbktm4mmQTpqpX3cnI',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545741,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'user',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': '有哪些作者？', 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': None,\n",
      "           'run_id': None,\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_Opx5NyEJiLxFLqzybgQAMOCM',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545676,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'assistant',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'The article introduces '\n",
      "                                          'Forward-Looking Active REtrieval '\n",
      "                                          'augmented generation (FLARE), a '\n",
      "                                          'method enhancing large language '\n",
      "                                          'models (LMs) to reduce '\n",
      "                                          'hallucinations and factually '\n",
      "                                          'incorrect outputs by actively '\n",
      "                                          'retrieving information during text '\n",
      "                                          'generation. Unlike traditional '\n",
      "                                          'retrieval-augmented LMs, which '\n",
      "                                          'fetch information once based on the '\n",
      "                                          'initial input, FLARE iteratively '\n",
      "                                          'predicts upcoming content to '\n",
      "                                          'retrieve relevant documents as '\n",
      "                                          'needed throughout the generation. '\n",
      "                                          'The approach addresses the '\n",
      "                                          'limitations of single-time '\n",
      "                                          'retrieval, particularly evident in '\n",
      "                                          'long-form, knowledge-intensive '\n",
      "                                          'tasks like long-form QA and '\n",
      "                                          'summarization. FLARE has been '\n",
      "                                          'tested extensively, showing '\n",
      "                                          'superior or competitive performance '\n",
      "                                          'on various long-form generation '\n",
      "                                          'tasks.',\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': 'asst_9OgwiVEppI8XRlEINALudBJ7',\n",
      "           'run_id': 'run_xyJA4T24pY2Uub93ZNemRPfP',\n",
      "           'metadata': {}},\n",
      "          {'id': 'msg_kNk9laIGxmDGd7Rh6j2zhLM8',\n",
      "           'object': 'thread.message',\n",
      "           'created_at': 1699545669,\n",
      "           'thread_id': 'thread_0LJ5hfJySHh8FHF7UK1b4kgv',\n",
      "           'role': 'user',\n",
      "           'content': [{'type': 'text',\n",
      "                        'text': {'value': 'write 100-word summary for this '\n",
      "                                          'article.',\n",
      "                                 'annotations': []}}],\n",
      "           'file_ids': [],\n",
      "           'assistant_id': None,\n",
      "           'run_id': None,\n",
      "           'metadata': {}}],\n",
      " 'first_id': 'msg_jvNyCQ4UaJRSZH6m7dtqQtHV',\n",
      " 'last_id': 'msg_kNk9laIGxmDGd7Rh6j2zhLM8',\n",
      " 'has_more': False}\n"
     ]
    }
   ],
   "source": [
    "## Get the assistant response from thread with message id\n",
    "\n",
    "headers = { \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\", \"Content-Type\": \"application/json\", \"OpenAI-Beta\": \"assistants=v1\" }\n",
    "\n",
    "response = requests.get(f\"https://api.openai.com/v1/threads/{thread_id}/messages\", headers = headers )\n",
    "\n",
    "obj = json.loads(response.text)\n",
    "\n",
    "pp(obj)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
